{
    "thought": "After reviewing the existing memory modules, it's evident that while similarity and contextual relevance are crucial, the dynamic adaptation based on the agent's current state and the environment's feedback is not fully leveraged. The proposed 'DynamicFeedbackMemory' module aims to integrate real-time feedback from the environment and the agent's actions to adjust the memory retrieval process dynamically. This module will not only store task trajectories but also the outcomes of actions taken based on those memories, allowing the system to learn which strategies are most effective in real-time. By incorporating a feedback loop that evaluates the effectiveness of each retrieved memory in the current context, the module can prioritize memories that have historically led to successful outcomes in similar scenarios. This approach ensures that the memory module is not just reactive but proactively adapts to enhance the agent's performance over time.",
    "name": "dynamic_feedback",
    "code": "class MemoryDynamicFeedback(MemoryBase):\n    def __init__(self, llms_type) -> None:\n        super().__init__(llms_type, 'dynamic_feedback')\n        self.feedback_scores = {}  # To track the effectiveness of each memory\n\n    def retriveMemory(self, query_scenario):\n        # Extract task name from query scenario\n        task_name = re.findall(r'Your task is to:\\s*(.*?)\\s*>', query_scenario)[2]\n        \n        # Return empty string if memory is empty\n        if self.scenario_memory._collection.count() == 0:\n            return ''\n            \n        # Find most similar memories\n        similarity_results = self.scenario_memory.similarity_search_with_score(\n            task_name, k=3)\n            \n        # Calculate weighted scores based on similarity and feedback\n        weighted_results = []\n        for result in similarity_results:\n            memory_id = result[0].metadata['memory_id']\n            similarity_score = result[1]\n            feedback_score = self.feedback_scores.get(memory_id, 0.5)  # Default to 0.5 if not found\n            weighted_score = similarity_score * feedback_score\n            weighted_results.append((result[0], weighted_score))\n        \n        # Sort memories by weighted score (descending)\n        weighted_results.sort(key=lambda x: x[1], reverse=True)\n        \n        # Return the trajectory with the highest weighted score\n        return weighted_results[0][0].metadata['task_trajectory']\n\n    def addMemory(self, current_situation):\n        # Extract task description\n        task_name = re.search(r'Your task is to:\\s*(.*?)\\s*>', current_situation).group(1)\n        memory_id = str(uuid.uuid4())\n        \n        # Create document with metadata\n        memory_doc = Document(\n            page_content=task_name,\n            metadata={\n                \"task_name\": task_name,\n                \"task_trajectory\": current_situation,\n                \"memory_id\": memory_id\n            }\n        )\n        \n        # Add to memory store\n        self.scenario_memory.add_documents([memory_doc])\n        \n        # Initialize feedback score for this memory\n        self.feedback_scores[memory_id] = 0.5\n    \n    def update_feedback(self, memory_id, success):\n        \"\"\"\n        Update the feedback score of a memory based on its effectiveness in the current task.\n        success: boolean indicating whether the memory was effective\n        \"\"\"\n        if memory_id in self.feedback_scores:\n            current_score = self.feedback_scores[memory_id]\n            # Update score with a simple moving average\n            new_score = current_score * 0.9 + (1 if success else 0) * 0.1\n            self.feedback_scores[memory_id] = new_score",
    "performance": 0.8
}